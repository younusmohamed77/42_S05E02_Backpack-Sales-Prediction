{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b812e7-fc52-4100-8893-f4cc1af25e5f",
   "metadata": {},
   "source": [
    "Supercode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02384ed-c32e-4779-b314-92252c9afb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Track execution time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f85c38-461a-48b4-993b-03348d924513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3994318 entries, 0 to 3994317\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   id                    int64  \n",
      " 1   Brand                 object \n",
      " 2   Material              object \n",
      " 3   Size                  object \n",
      " 4   Compartments          float64\n",
      " 5   Laptop Compartment    object \n",
      " 6   Waterproof            object \n",
      " 7   Style                 object \n",
      " 8   Color                 object \n",
      " 9   Weight Capacity (kg)  float64\n",
      " 10  Price                 float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 335.2+ MB\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    200000 non-null  int64  \n",
      " 1   Brand                 193773 non-null  object \n",
      " 2   Material              194387 non-null  object \n",
      " 3   Size                  195619 non-null  object \n",
      " 4   Compartments          200000 non-null  float64\n",
      " 5   Laptop Compartment    195038 non-null  object \n",
      " 6   Waterproof            195189 non-null  object \n",
      " 7   Style                 194847 non-null  object \n",
      " 8   Color                 193215 non-null  object \n",
      " 9   Weight Capacity (kg)  199923 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 15.3+ MB\n",
      "\n",
      "Missing Values in Train Data:\n",
      " id                           0\n",
      "Brand                   126758\n",
      "Material                110962\n",
      "Size                     87785\n",
      "Compartments                 0\n",
      "Laptop Compartment       98533\n",
      "Waterproof               94324\n",
      "Style                   104180\n",
      "Color                   133617\n",
      "Weight Capacity (kg)      1808\n",
      "Price                        0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Test Data:\n",
      " id                         0\n",
      "Brand                   6227\n",
      "Material                5613\n",
      "Size                    4381\n",
      "Compartments               0\n",
      "Laptop Compartment      4962\n",
      "Waterproof              4811\n",
      "Style                   5153\n",
      "Color                   6785\n",
      "Weight Capacity (kg)      77\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Material</th>\n",
       "      <th>Size</th>\n",
       "      <th>Compartments</th>\n",
       "      <th>Laptop Compartment</th>\n",
       "      <th>Waterproof</th>\n",
       "      <th>Style</th>\n",
       "      <th>Color</th>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Black</td>\n",
       "      <td>11.611723</td>\n",
       "      <td>112.15875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Small</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>27.078537</td>\n",
       "      <td>68.88056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Red</td>\n",
       "      <td>16.643760</td>\n",
       "      <td>39.17320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Small</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>12.937220</td>\n",
       "      <td>80.60793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>17.749338</td>\n",
       "      <td>86.02312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         Brand Material    Size  Compartments Laptop Compartment  \\\n",
       "0   0      Jansport  Leather  Medium           7.0                Yes   \n",
       "1   1      Jansport   Canvas   Small          10.0                Yes   \n",
       "2   2  Under Armour  Leather   Small           2.0                Yes   \n",
       "3   3          Nike    Nylon   Small           8.0                Yes   \n",
       "4   4        Adidas   Canvas  Medium           1.0                Yes   \n",
       "\n",
       "  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n",
       "0         No       Tote  Black             11.611723  112.15875  \n",
       "1        Yes  Messenger  Green             27.078537   68.88056  \n",
       "2         No  Messenger    Red             16.643760   39.17320  \n",
       "3         No  Messenger  Green             12.937220   80.60793  \n",
       "4        Yes  Messenger  Green             17.749338   86.02312  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "extra_train_df = pd.read_csv(\"training_extra.csv\")\n",
    "\n",
    "train_df = pd.concat([train_df, extra_train_df], ignore_index=True)\n",
    "train_df\n",
    "\n",
    "# Display basic info\n",
    "print(\"Train Data Info:\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"\\nTest Data Info:\")\n",
    "test_df.info()\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nMissing Values in Train Data:\\n\", train_df.isnull().sum())\n",
    "print(\"\\nMissing Values in Test Data:\\n\", test_df.isnull().sum())\n",
    "\n",
    "# Display first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4393d60-9813-4201-a88a-3eb3329d60dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Done!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Preprocess the data: Handle missing values, encode categorical features, and scale numerical features.\n",
    "    \"\"\"\n",
    "    # Drop ID column\n",
    "    train_df.drop(\"id\", axis=1, inplace=True)\n",
    "    test_ids = test_df[\"id\"]\n",
    "    test_df.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "    # Separate target variable\n",
    "    y = train_df[\"Price\"]\n",
    "    X = train_df.drop(\"Price\", axis=1)\n",
    "\n",
    "    # Identify categorical & numerical columns\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "    # Fill missing values\n",
    "    for col in categorical_cols:\n",
    "        X[col].fillna(X[col].mode()[0], inplace=True)\n",
    "        test_df[col].fillna(test_df[col].mode()[0], inplace=True)\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        X[col].fillna(X[col].median(), inplace=True)\n",
    "        test_df[col].fillna(test_df[col].median(), inplace=True)\n",
    "\n",
    "    # Encoding strategy\n",
    "    encoders = []\n",
    "    for col in categorical_cols:\n",
    "        if X[col].nunique() <= 10:\n",
    "            encoders.append((col, OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)))\n",
    "        else:\n",
    "            encoders.append((col, OneHotEncoder(handle_unknown=\"ignore\")))\n",
    "\n",
    "    # Define Column Transformer\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), numerical_cols),\n",
    "        (\"cat\", Pipeline(encoders), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    # Apply transformations\n",
    "    X = preprocessor.fit_transform(X)\n",
    "    test_df = preprocessor.transform(test_df)\n",
    "\n",
    "    return X, y, test_df, test_ids, preprocessor\n",
    "\n",
    "# Apply preprocessing\n",
    "X, y, X_test, test_ids, preprocessor = preprocess_data(train_df, test_df)\n",
    "print(\"Preprocessing Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b21f8b6-35a5-4c83-ae26-ee898bc939f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc200c-9013-48af-ad13-5588e465f151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: RMSE = 38.9079\n",
      "Time elapsed: 50.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  14%|█▍        | 1/7 [00:00<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created for Linear Regression.\n",
      "Ridge Regression: RMSE = 38.9079\n",
      "Time elapsed: 50.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  29%|██▊       | 2/7 [00:01<00:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created for Ridge Regression.\n",
      "Lasso Regression: RMSE = 38.9083\n",
      "Time elapsed: 51.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  43%|████▎     | 3/7 [00:01<00:02,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created for Lasso Regression.\n",
      "Random Forest: RMSE = 40.5056\n",
      "Time elapsed: 3501.25 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  57%|█████▋    | 4/7 [58:18<1:09:02, 1380.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created for Random Forest.\n",
      "Gradient Boosting: RMSE = 38.8797\n",
      "Time elapsed: 4126.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  71%|███████▏  | 5/7 [1:07:57<36:23, 1091.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created for Gradient Boosting.\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"SVR\": SVR(),\n",
    "    \"MLP Regressor\": MLPRegressor(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in tqdm(models.items(), desc=\"Training Models\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    results[name] = rmse\n",
    "    print(f\"{name}: RMSE = {rmse:.4f}\")\n",
    "    print(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Save submission\n",
    "    test_preds = model.predict(X_test)\n",
    "    submission = pd.DataFrame({\"id\": test_ids, \"Price\": test_preds})\n",
    "    submission.to_csv(f\"submission_{name}.csv\", index=False)\n",
    "    print(f\"Submission file created for {name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637c9b4-8fe1-41dd-9d00-2167d6505ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(trial, model_name):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "    }\n",
    "\n",
    "    if model_name == \"XGBoost\":\n",
    "        model = xgb.XGBRegressor(tree_method=\"gpu_hist\", **params)\n",
    "    elif model_name == \"LightGBM\":\n",
    "        model = lgb.LGBMRegressor(device=\"gpu\", **params)\n",
    "    else:\n",
    "        model = cb.CatBoostRegressor(task_type=\"GPU\", verbose=0, **params)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "best_params = {}\n",
    "for model_name in [\"XGBoost\", \"LightGBM\", \"CatBoost\"]:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: optimize_model(trial, model_name), n_trials=20)\n",
    "    best_params[model_name] = study.best_params\n",
    "    print(f\"Best {model_name} Params:\", best_params[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae60170-d969-49f7-98a9-add883843e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in best_models.items():\n",
    "    model.fit(X, y)\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    submission = pd.DataFrame({\"id\": test_ids, \"Price\": test_preds})\n",
    "    submission.to_csv(f\"submission_{name}.csv\", index=False)\n",
    "    print(f\"Submission file created for {name}. Time elapsed: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf1f7c-59ee-43f1-9579-a3a82bacdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f\"\\nTotal Execution Time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a95e6a-211f-4f28-9187-7086734cb8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
